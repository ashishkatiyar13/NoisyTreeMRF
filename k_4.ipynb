{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "k_4_submission_v1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "shfMGDnBHvyj"
      },
      "source": [
        "import numpy.random as rand\n",
        "import numpy as np\n",
        "import numpy.linalg as la\n",
        "import timeit\n",
        "import time\n",
        "from numpy.linalg import inv\n",
        "import math\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import ortho_group\n",
        "import heapq\n",
        "import copy\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "from google.colab import drive \n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVunAT8Wac8m"
      },
      "source": [
        "# **Organization of the file**\n",
        "\n",
        "The code can be broadly classified in three parts:\n",
        "1.   The fist part focuses on implementing graph theoretic functions like the minimum spanning tree, equivalence class, etc.\n",
        "2.   The second part implements the generation of the samples and other quantities which are empirically estimated.\n",
        "3.   The third part contains the all the nuts and bolts of our algorithm as well as the complete execution of the algorithm.\n",
        "\n",
        "\n",
        "To run the code, set the desired parameters in the init_paramters() function. Then, call the main() function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXsKG6f4_dym"
      },
      "source": [
        "# **Graph structure algorithms section**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t-DC1TSRgv0"
      },
      "source": [
        "\"\"\"\n",
        "Minimum Spanning Tree subroutine borrowed from : https://www.geeksforgeeks.org/kruskals-minimum-spanning-tree-algorithm-greedy-algo-2/\n",
        "\"\"\"\n",
        "# Minimum Spanning Tree of a given connected,\n",
        "# undirected and weighted graph\n",
        " \n",
        "from collections import defaultdict\n",
        " \n",
        "# Class to represent a graph\n",
        " \n",
        " \n",
        "class Graph:\n",
        " \n",
        "    def __init__(self, vertices):\n",
        "        self.V = vertices  # No. of vertices\n",
        "        self.graph = []  # default dictionary\n",
        "        # to store graph\n",
        " \n",
        "    # function to add an edge to graph\n",
        "    def addEdge(self, u, v, w):\n",
        "        self.graph.append([u, v, w])\n",
        " \n",
        "    # A utility function to find set of an element i\n",
        "    # (uses path compression technique)\n",
        "    def find(self, parent, i):\n",
        "        if parent[i] == i:\n",
        "            return i\n",
        "        return self.find(parent, parent[i])\n",
        " \n",
        "    # A function that does union of two sets of x and y\n",
        "    # (uses union by rank)\n",
        "    def union(self, parent, rank, x, y):\n",
        "        xroot = self.find(parent, x)\n",
        "        yroot = self.find(parent, y)\n",
        " \n",
        "        # Attach smaller rank tree under root of\n",
        "        # high rank tree (Union by Rank)\n",
        "        if rank[xroot] < rank[yroot]:\n",
        "            parent[xroot] = yroot\n",
        "        elif rank[xroot] > rank[yroot]:\n",
        "            parent[yroot] = xroot\n",
        " \n",
        "        # If ranks are same, then make one as root\n",
        "        # and increment its rank by one\n",
        "        else:\n",
        "            parent[yroot] = xroot\n",
        "            rank[xroot] += 1\n",
        " \n",
        "    # The main function to construct MST using Kruskal's\n",
        "        # algorithm\n",
        "    def KruskalMST(self):\n",
        " \n",
        "        result = []  # This will store the resultant MST\n",
        "         \n",
        "        # An index variable, used for sorted edges\n",
        "        i = 0\n",
        "         \n",
        "        # An index variable, used for result[]\n",
        "        e = 0\n",
        " \n",
        "        # Step 1:  Sort all the edges in \n",
        "        # non-decreasing order of their\n",
        "        # weight.  If we are not allowed to change the\n",
        "        # given graph, we can create a copy of graph\n",
        "        self.graph = sorted(self.graph, \n",
        "                            key=lambda item: item[2])\n",
        " \n",
        "        parent = []\n",
        "        rank = []\n",
        " \n",
        "        # Create V subsets with single elements\n",
        "        for node in range(self.V):\n",
        "            parent.append(node)\n",
        "            rank.append(0)\n",
        " \n",
        "        # Number of edges to be taken is equal to V-1\n",
        "        while e < self.V - 1:\n",
        " \n",
        "            # Step 2: Pick the smallest edge and increment\n",
        "            # the index for next iteration\n",
        "            u, v, w = self.graph[i]\n",
        "            i = i + 1\n",
        "            x = self.find(parent, u)\n",
        "            y = self.find(parent, v)\n",
        " \n",
        "            # If including this edge does't\n",
        "            #  cause cycle, include it in result \n",
        "            #  and increment the indexof result \n",
        "            # for next edge\n",
        "            if x != y:\n",
        "                e = e + 1\n",
        "                result.append([u, v])\n",
        "                self.union(parent, rank, x, y)\n",
        "            # Else discard the edge\n",
        " \n",
        "        return result\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2hjyxZmMA-A"
      },
      "source": [
        "class Tree:\n",
        "\n",
        "    def __init__(self, num_nodes, shape):\n",
        "        self.num_nodes = num_nodes\n",
        "        self.shape = shape\n",
        "        self.edges = []\n",
        "    \n",
        "    \"\"\"\n",
        "    Given a matrix of pairwise mutual information, find the CL tree.\n",
        "\n",
        "    Input:\n",
        "    Pairwise mutual information matrix - mi_mat\n",
        "\n",
        "    Output:\n",
        "    List of edges for the maximum spanning tree.\n",
        "    \"\"\"\n",
        "    def chow_liu_tree(self, mi_mat):\n",
        "        g = Graph(self.num_nodes)\n",
        "        for i in range(self.num_nodes-1):\n",
        "            for j in range(i+1,self.num_nodes):\n",
        "                g.addEdge(i, j, -mi_mat[i,j])\n",
        "        return g.KruskalMST()\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Given a shape argument, return the edges.\n",
        "\n",
        "    Input:\n",
        "    Tree shape that takes values among \"star\", \"chain\", \"random\" - shape \n",
        "\n",
        "    Output:\n",
        "    Edges of the tree as a list of lists where each list has 2 nodes which have an edge - edges\n",
        "    \"\"\"\n",
        "    def gen_edges(self):\n",
        "        self.edges = []\n",
        "        if self.shape == 'star':\n",
        "            # Node 0 is the center node and the remaining nodes are connected to node 0.\n",
        "            for i in range(self.num_nodes-1):\n",
        "                self.edges.append([i+1,0])\n",
        "        if self.shape == 'chain':\n",
        "            # Edges between node i and i+1\n",
        "            for i in range(self.num_nodes-1):\n",
        "                self.edges.append([i,i+1])\n",
        "        if self.shape == \"random\":\n",
        "            # To get a random graph, generate an arbitrary weight matrix and find its spanning tree.\n",
        "            rand_mat = rand.uniform(size = [self.num_nodes,self.num_nodes])\n",
        "            self.edges = self.chow_liu_tree(rand_mat)\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Convert a list of edges to adjacency matrix.\n",
        "\n",
        "    Input:\n",
        "    List of edges - list_edges\n",
        "\n",
        "    Output:\n",
        "    Adjacency Matrix - adj\n",
        "    \"\"\"\n",
        "    def _edges_to_adj(self, list_edges):\n",
        "        n = len(list_edges) + 1\n",
        "        adj = np.zeros(shape=[n,n])\n",
        "        for i in list_edges:\n",
        "            adj[i[0], i[1]] = 1\n",
        "            adj[i[1], i[0]] = 1\n",
        "        return adj\n",
        "\n",
        "    \"\"\"\n",
        "    Find leaf clusters from adjacency matrix. Also find the adjacency matrix for leaf clusters.\n",
        "\n",
        "    Input:\n",
        "    Adacency matrix for the edges - adj\n",
        "\n",
        "    Output:\n",
        "    A list of lists where each list contains the nodes within a leaf cluster - LC\n",
        "    Adjacency matrix for the leaf clusters (two leaf clusters have an edge of there is an edge between the nodes in the leaf clusters) - LC_adj\n",
        "    \"\"\"\n",
        "    def _adj_to_LC(self,adj):\n",
        "        LC = []\n",
        "        leaves = set([])\n",
        "        for i in range(self.num_nodes):\n",
        "            if sum(adj[i,:]) == 1:\n",
        "                leaves.add(i)\n",
        "        D = {}\n",
        "        LC_edges = []\n",
        "        for i in range(self.num_nodes):\n",
        "            if i in leaves:\n",
        "                continue\n",
        "            D[i] = len(LC)\n",
        "            LC.append([i])\n",
        "            for j in range(self.num_nodes):\n",
        "                if adj[i,j] == 1: \n",
        "                    if j in leaves:\n",
        "                        LC[-1].append(j)\n",
        "                    elif j in D:\n",
        "                        LC_edges.append([D[i],D[j]])\n",
        "        LC_adj = self._edges_to_adj(LC_edges)\n",
        "        return LC,LC_adj\n",
        "\n",
        "    \"\"\"\n",
        "    Generate the list of trees in the equivalence class from the leaf clusters and leaf cluster adjacency matrix.\n",
        "\n",
        "    Input:\n",
        "    Leaf Clusters - LC\n",
        "    Leaf Cluster Adjacency Matrix - LC_adj\n",
        "    \"\"\"\n",
        "    def _edges_lc_to_tree_set(self, LC, LC_adj):\n",
        "        # If there is just one leaf cluster, return all the trees with each node taking turns being the parent node.\n",
        "        if len(LC) == 1:\n",
        "            trees = []\n",
        "            for i in LC[0]:\n",
        "                tree = [[]]\n",
        "                tree[0].append(i)\n",
        "                for j in LC[0]:\n",
        "                    if i == j:\n",
        "                        continue\n",
        "                    tree.append([i,j])\n",
        "                trees.append(tree)\n",
        "            return trees\n",
        "        len_LC = len(LC)\n",
        "        # Obtain the equivalence class excluding the last leaf cluster.\n",
        "        prev_trees = self._edges_lc_to_tree_set(LC[:-1], LC_adj[:-1, :-1])\n",
        "        curr_LC = LC[-1]\n",
        "        trees = []\n",
        "        for tree in prev_trees:\n",
        "            for j in LC[-1]:\n",
        "                tree_copy = copy.deepcopy(tree)\n",
        "                tree_copy[0].append(j)\n",
        "                # Add edges within the last leaf cluster\n",
        "                for k in LC[-1]:\n",
        "                    if k == j:\n",
        "                        continue\n",
        "                    tree_copy.append([k,j])\n",
        "                # Add edges between the last leaf cluster and its adjacent leaf clusters\n",
        "                for i in range(len_LC):\n",
        "                  if LC_adj[-1, i] == 1:\n",
        "                    tree_copy.append([tree_copy[0][i], j])\n",
        "                trees.append(tree_copy)\n",
        "        return trees\n",
        "\n",
        "    \"\"\"\n",
        "    Given a list of edges, find the list of trees in the Equivalence Class.\n",
        "\n",
        "    Input: \n",
        "    List of Edges - edges\n",
        "\n",
        "    Output:\n",
        "    List of trees in the equivalence class - tree_list\n",
        "    \"\"\"\n",
        "    def edges_to_EC(self):\n",
        "        tree_list = []\n",
        "        adj = self._edges_to_adj(self.edges)\n",
        "        LC, LC_adj = self._adj_to_LC(adj)\n",
        "        trees = self._edges_lc_to_tree_set(LC, LC_adj)\n",
        "        for tree in trees:\n",
        "            tree_edges = tree[1:]\n",
        "            tree_list.append(set([frozenset(i) for i in tree_edges]))\n",
        "        return tree_list\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    If the nodes were randomly relabeled before feeding in the algorithm, use this to obtain the original labels back.\n",
        "\n",
        "    Input:\n",
        "    List of relabeled edges - list_edges\n",
        "    Permutation used to relabel the nodes - permutation\n",
        "\n",
        "    Output:\n",
        "    List of originally labeled edges - new_edges\n",
        "    \"\"\"\n",
        "    def invert_permute(self, list_edges, permutation):\n",
        "        new_edges = []\n",
        "        for i in list_edges:\n",
        "            new_edges.append([permutation[i[0]], permutation[i[1]]])\n",
        "        return new_edges\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Transform the edges from a list of lists to a set of sets for easy testing of equality of two trees.\n",
        "    \"\"\"\n",
        "    def edges_as_set_of_sets(self, list_edges):\n",
        "        edges_set = set([frozenset(i) for i in list_edges])\n",
        "        return edges_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9jBBPy0Fqcs"
      },
      "source": [
        "# **Graphical Model Sampling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtn48G8uxYW0"
      },
      "source": [
        "class MRF_sampling:\n",
        "\n",
        "    def __init__(self, num_samples, cond_det_low, cond_det_high, q_max, edges, supp_size, delta):\n",
        "        self.cond_det_low = cond_det_low\n",
        "        self.cond_det_high = cond_det_high\n",
        "        self.q_max = q_max\n",
        "        self.edges = edges\n",
        "        self.supp_size = supp_size\n",
        "        self.delta = delta\n",
        "        self.num_samples = num_samples\n",
        "        self.num_nodes = len(edges) + 1\n",
        "        self.cond_dists = []\n",
        "        self.pmf = None\n",
        "        self.prob_err = None\n",
        "        self.clean_samples = None\n",
        "        self.noisy_samples = None\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Convert a sample from integer in [0, 4^d - 1) to a 'd' dimensional vector with elements in [0,1,2,3].\n",
        "\n",
        "    Inputs: \n",
        "    Integer in [0, 4^d - 1) - i\n",
        "    Dimension - self.num_nodes\n",
        "\n",
        "    Output: \n",
        "    vector with elements in [0,1,2,3] - ans\n",
        "    \"\"\"\n",
        "    def _num_to_vec(self, i):\n",
        "        ans = [-1]*self.num_nodes\n",
        "        for j in range(self.num_nodes):\n",
        "            ans[self.num_nodes-1-j] = int(i%4)\n",
        "            i = int(i/4)\n",
        "        return tuple(ans)\n",
        "\n",
        "    \"\"\"\n",
        "    Generate conditional distribution for adjacent nodes in a graphical model with d nodes according to a perturbed symmetric model.\n",
        "    All the adjacent nodes have equal distance self.cond_det_low. The parameter delta is given and alpha is estimated.\n",
        "\n",
        "    Output:\n",
        "    List of num_nodes-1 conditional distributions - cond_dists\n",
        "    \"\"\"\n",
        "\n",
        "    def gen_cond_dist_perturbed_symmetric(self):\n",
        "        poly_arr = []\n",
        "        for i in range(self.supp_size):\n",
        "            poly_arr.append(math.factorial(self.supp_size)//(math.factorial(self.supp_size-i)*math.factorial(i))*(-self.delta)**i)\n",
        "        poly_arr[-1] = poly_arr[-1] - self.cond_det_low\n",
        "        p = np.poly1d(poly_arr)\n",
        "        alpha_arr = p.r\n",
        "        final_mat, min_err = np.zeros(shape = [self.supp_size, self.supp_size]), 10\n",
        "        for alpha_cand in alpha_arr:\n",
        "            alpha_can_real = alpha_cand.real\n",
        "            D = np.zeros(shape = [self.supp_size, self.supp_size])\n",
        "            for i in range(self.supp_size):\n",
        "                D[i,(i+1)%self.supp_size] = self.delta\n",
        "            mat = (alpha_can_real - self.delta)*np.identity(self.supp_size)+ D + (1-alpha_can_real)/self.supp_size*np.ones(shape = [self.supp_size, self.supp_size])\n",
        "            if abs(la.det(mat) - self.cond_det_low)<min_err:\n",
        "                final_mat[:,:] = mat[:,:]\n",
        "                min_err = abs(la.det(mat) - self.cond_det_low)\n",
        "        for i in range(self.num_nodes-1):            \n",
        "            self.cond_dists.append(final_mat)\n",
        "    \"\"\"\n",
        "    Given a list of edges, convert then into an adjacency list. Adjaceny list is a dictionary indexed by the nodes as keys and the values are the list of edges for each key.\n",
        "    This enables us to perform efficient BFS which further enables efficient sampling from the graphical model.\n",
        "    Input:\n",
        "    List of edges - edges\n",
        "\n",
        "    Output:\n",
        "    Adjacency List - adj_l\n",
        "    \"\"\"\n",
        "    def _edges_to_adj_list(self):\n",
        "        adj_l = {}\n",
        "        for i in self.edges:\n",
        "            if i[0] not in adj_l:\n",
        "                adj_l[i[0]] = [i[1]]\n",
        "            else:\n",
        "                adj_l[i[0]].append(i[1])\n",
        "            if i[1] not in adj_l:\n",
        "                adj_l[i[1]] = [i[0]]\n",
        "            else:\n",
        "                adj_l[i[1]].append(i[0])\n",
        "        return adj_l\n",
        "        \n",
        "    \"\"\"\n",
        "    Given an adjacency list, this function returns the order in which the edges would be traversed if Breadth first search(BFS) is used to scan the nodes.\n",
        "    For each node, we record the order in which it was traversed and which node was its parent node. This order is used when generating the PMF of the graphical model.\n",
        "    It is also used when generating samples directly without generating the PMF.\n",
        "\n",
        "    Input:\n",
        "    Adjacency List: adj_l\n",
        "\n",
        "    Output:\n",
        "    Order of traversal: order\n",
        "    \"\"\"\n",
        "    def _bfs(self, adj_l):\n",
        "        q = deque()\n",
        "        visited = [0]\n",
        "        order = []\n",
        "        q.append(0)\n",
        "        iter = 0\n",
        "        while(q):\n",
        "            node = q.popleft()\n",
        "            for i in adj_l[node]:\n",
        "                if i in visited:\n",
        "                    continue\n",
        "                order.append([i, node, iter])\n",
        "                q.append(i)\n",
        "                visited.append(i)\n",
        "                iter+=1\n",
        "        return order\n",
        "\n",
        "    \"\"\"\n",
        "    Given a configuration of the nodes, find its PMF. The idea is to assign the 0th node equal probability for each support. Then go in the order obtained from BFS to generate \n",
        "    probability conditioned on each node's parent.\n",
        "\n",
        "    Inputs: \n",
        "    Configuration of the nodes - x\n",
        "    Conditional distribution matrices - cond_dists\n",
        "    Order of Traveral - order\n",
        "\n",
        "    Output:\n",
        "    PMF for a given configuration - prob\n",
        "    \"\"\"\n",
        "    def _input_to_prob(self, x, order):\n",
        "        prob = 1/4\n",
        "        for i in order:\n",
        "            prob *= self.cond_dists[i[2]][x[i[1]], x[i[0]]]\n",
        "        return prob\n",
        "\n",
        "    \"\"\"\n",
        "    Generate the PMF of a graphical model given a list of conditional PMFs and a list of edges.\n",
        "\n",
        "    Input:\n",
        "    List of conditional PMFs - cond_dists\n",
        "    List of edges - edges\n",
        "\n",
        "    Output:\n",
        "    PMF vector - pmf\n",
        "    \"\"\"\n",
        "      \n",
        "    def gen_pmf(self):\n",
        "        adj_l = self._edges_to_adj_list()\n",
        "        order = self._bfs(adj_l)\n",
        "        self.pmf = np.ones(4**self.num_nodes)\n",
        "        vec_num_to_vec = np.vectorize(self._num_to_vec)\n",
        "        x_mat = np.transpose(np.array(vec_num_to_vec(np.arange(4**self.num_nodes))))\n",
        "        self.pmf = np.apply_along_axis(self._input_to_prob, 1, x_mat, order)\n",
        "        self.pmf = self.pmf/sum(self.pmf)\n",
        "\n",
        "    \n",
        "    \"\"\"\n",
        "    Generate random samples given a probability mass function.\n",
        "\n",
        "    Inputs: \n",
        "    Probability mass function - pmf, \n",
        "    Number of samples - num_samples\n",
        "    Dimension - num_nodes\n",
        "\n",
        "    Output: \n",
        "    Samples (shape - [num_samples x num_nodes] ) - clean_samples\n",
        "    \"\"\"\n",
        "\n",
        "    def gen_clean_samples_1(self):\n",
        "        samples = rand.choice(4**self.num_nodes, size = (self.num_samples,), replace = True, p = self.pmf)\n",
        "        self.clean_samples = np.ones((self.num_samples, self.num_nodes))\n",
        "        for i in range(len(samples)):\n",
        "            self.clean_samples[i, :] = self._num_to_vec(samples[i])\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Given a sample for 0th node, generate samples for the remaining nodes.\n",
        "\n",
        "    Input:\n",
        "    Sample for the 0th node - x\n",
        "    List of conditional PMFs - cond_dists\n",
        "    Order of traversal - order\n",
        "\n",
        "    Output:\n",
        "    A sample vector - sample\n",
        "\n",
        "    \"\"\"\n",
        "    def _gen_samples_cond_0(self, x, order):\n",
        "        sample = np.zeros(d, dtype = int)\n",
        "        sample[0] = x\n",
        "        for i in order:\n",
        "            sample[i[0]] = rand.choice(4, p = self.cond_dists[i[2]][sample[i[1]],:])\n",
        "        return sample\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Given a list of conditional distributions and edges, sample from the graphical model. Note that in this process we don't calculate the complete PMF which is an operation\n",
        "    exponential in the number of nodes.\n",
        "\n",
        "    Input:\n",
        "    List of conditional PMFs - cond_dists\n",
        "    List of edges - edges\n",
        "    Number of samples - num_samples\n",
        "\n",
        "    Output:\n",
        "    Graphical model samples - samples\n",
        "    \"\"\"\n",
        "    def gen_clean_samples_2(self):\n",
        "        adj_l = self._edges_to_adj_list(self.edges)\n",
        "        order = self._bfs(adj_l)\n",
        "        samples_0 = rand.choice(4, size=[self.num_samples,1])\n",
        "        self.clean_samples = np.apply_along_axis(self._gen_samples_cond_0, 1, samples_0, order)\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Given clean samples, this function returns the output when the clean samples pass through a 3-ary symmetric channel.\n",
        "\n",
        "    Input: \n",
        "    Clean samples - samples (shape - [num_samples x num_nodes])\n",
        "    Probability of error for each dimension - prob_err \n",
        "\n",
        "    Output:\n",
        "    Noisy samples - noisy_samples\n",
        "    \"\"\"\n",
        "    def gen_noisy_samples(self):\n",
        "        prob_err = rand.uniform(0, self.q_max, size = (self.num_nodes,))\n",
        "        self.noisy_samples = np.copy(self.clean_samples)\n",
        "        random_samples = rand.choice(4, size = [self.num_samples, self.num_nodes])\n",
        "        mask = np.zeros(shape = [self.num_samples, self.num_nodes], dtype=bool)\n",
        "        for i in range(self.num_nodes):\n",
        "            mask[:,i] = rand.choice(a = [True, False], p = [prob_err[i], 1-prob_err[i]], size = self.num_samples)\n",
        "        self.noisy_samples[mask] = random_samples[mask]\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kgvlcxg1FxRl"
      },
      "source": [
        "# **Algorithm to recover the tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjl0_nNwInAU"
      },
      "source": [
        "class RecoverTree():\n",
        "\n",
        "    def __init__(self, noisy_samples, permutation, thres_quad, thres_prox, thres_star, ideal_thres_prox, q_max, supp_size):\n",
        "        self.noisy_samples = noisy_samples\n",
        "        self.num_nodes = noisy_samples.shape[1]\n",
        "        self.num_samples = noisy_samples.shape[0]\n",
        "        self.permutation = permutation\n",
        "        self._thres_prox = thres_prox\n",
        "        self._thres_quad = thres_quad\n",
        "        self._thres_star = thres_star\n",
        "        self.ideal_thres_prox = ideal_thres_prox\n",
        "        self.q_max = q_max\n",
        "        self.supp_size = supp_size\n",
        "\n",
        "    \"\"\"\n",
        "    Finds the empirical pairwise distribution from the samples.\n",
        "\n",
        "    Inputs: \n",
        "    Samples from which the empirical distribution is calculated - samples\n",
        "    Dimension - num_nodes\n",
        "\n",
        "    Outputs:\n",
        "    A num_nodes x num_nodes list of empirical PMF matrices where i,j entry is the joint distribution of i^th and j^th random variables - _emp_distribution\n",
        "    \"\"\"\n",
        "    def _gen_sample_dist(self):\n",
        "        self._emp_distribution = [[None for _ in range(self.num_nodes)]for _ in range(self.num_nodes)]\n",
        "        for i in range(self.num_nodes):\n",
        "            for j in range(self.num_nodes):\n",
        "                P = np.zeros(shape = [4,4])\n",
        "                for k1 in range(4):\n",
        "                    for k2 in range(4):\n",
        "                        mask = (self.noisy_samples[:,self.permutation[i]] == k1) & (self.noisy_samples[:,self.permutation[j]] == k2)\n",
        "                        P[k1, k2] = np.mean(mask)\n",
        "                self._emp_distribution[i][j] = P\n",
        "\n",
        "    \"\"\"\n",
        "    Generate neighnorhood sets.\n",
        "\n",
        "    Inputs:\n",
        "    Empirical joint pairwise PMF - _emp_distribution\n",
        "\n",
        "    Outputs:\n",
        "    A list of lists where each list is the set of neighborhood nodes saved as a tuple - _prox\n",
        "    A list of sets containing the nodes in every node's neighborhood - _prox_set\n",
        "\n",
        "    \"\"\"\n",
        "    def _get_prox(self):\n",
        "        bin_p = False       # This is a flag for debug printing\n",
        "        self._prox = []\n",
        "        self._prox_set = []\n",
        "        for i in range(self.num_nodes):\n",
        "            h = []\n",
        "            s = set([])\n",
        "            for j in range(self.num_nodes):\n",
        "                if j==i:\n",
        "                    continue\n",
        "                if bin_p:\n",
        "                    print(self._emp_exp_distance[i,j], self._thres_prox)\n",
        "                if self._emp_exp_distance[i,j] > self._thres_prox:\n",
        "                    heapq.heappush(h, (-abs(self._emp_exp_distance[i,j]), j))\n",
        "                    s.add(j)\n",
        "            self._prox.append(h)\n",
        "            self._prox_set.append(s)\n",
        "  \n",
        "    \"\"\"\n",
        "    Finds the empirical pairwise exponential of negative distances given the empirical probability distribution.\n",
        "\n",
        "    Input: \n",
        "    Pairwise empirical distribution - _emp_distribution\n",
        "\n",
        "    Output -\n",
        "    Empirical pairwise negative exponential distances - _emp_exp_distance\n",
        "\n",
        "    \"\"\"\n",
        "    def _pairwise_exp_distance(self):\n",
        "        self._emp_exp_distance = np.zeros(shape = [self.num_nodes,self.num_nodes])\n",
        "        for i in range(self.num_nodes):\n",
        "            for j in range(self.num_nodes):\n",
        "                if j == i:\n",
        "                    continue\n",
        "                self._emp_exp_distance[i,j] = abs(la.det(self._emp_distribution[i][j]))/np.sqrt(la.det(self._emp_distribution[i][i])*la.det(self._emp_distribution[j][j]))\n",
        "        # If we do not assume knowledge of the ideal parameters, we estimate them here.\n",
        "        if not self.ideal_thres_prox:\n",
        "            min_det = np.min(np.max(self._emp_exp_distance, axis = 1))\n",
        "            self._thres_prox = min_det**4*(1-self.q_max)**(3*(self.supp_size - 1))*0.5\n",
        "\n",
        "    \"\"\"\n",
        "    Finds the empirical pairwise mutual information given the empirical probability distribution. This is used when running the Chow-Liu Algorithm\n",
        "\n",
        "    Input: \n",
        "    Pairwise empirical distribution - _emp_distribution\n",
        "\n",
        "    Output:\n",
        "    Empirical pairwise mutual information - emp_mut_info\n",
        "    \"\"\"\n",
        "    def pairwise_mut_info(self):\n",
        "        self.emp_mut_info = np.zeros(shape = [self.num_nodes,self.num_nodes])\n",
        "        entropy = np.zeros(self.num_nodes)\n",
        "        # eps is added to avoid log 0\n",
        "        eps = 1e-6\n",
        "        for i in range(self.num_nodes):\n",
        "            for j in range(4):\n",
        "                entropy[i] += -self._emp_distribution[i][i][j,j]*np.log2(self._emp_distribution[i][i][j,j]+1e-6)\n",
        "        for i in range(self.num_nodes):\n",
        "            for j in range(self.num_nodes):\n",
        "                if i==j:\n",
        "                    continue\n",
        "                joint_entropy = 0\n",
        "                for k1 in range(4):\n",
        "                    for k2 in range(4):\n",
        "                        joint_entropy += -self._emp_distribution[i][j][k1,k2]*np.log2(self._emp_distribution[i][j][k1,k2]+1e-6)\n",
        "                self.emp_mut_info[i,j] = entropy[i] + entropy[j] - joint_entropy\n",
        "\n",
        "    \"\"\"\n",
        "    Checks if a set of 4 nodes is non-star structured. If it is, it returns the separation of the nodes in 2 groups of 2 nodes each.\n",
        "\n",
        "    Input:\n",
        "    The empirical pairwise of all the nodes - _emp_dist\n",
        "    The set of 4 nodes that are checked for star/non-star - nodes\n",
        "    Output:\n",
        "    If the set of 4 nodes is non-star or not - non_star\n",
        "    If they are, return the two pairs - fin_pair1, fin_pair2\n",
        "    If not return empty lists - [], []\n",
        "\n",
        "    \"\"\"\n",
        "    def _is_non_star(self, nodes):\n",
        "        bin_p = True       # This is a flag for debug printing.\n",
        "        bin_p = False\n",
        "        non_star = False\n",
        "        fin_pair1 = [-1,-1]\n",
        "        fin_pair2 = [-1,-1]\n",
        "        v = np.array([0.0,0.0,0.0])\n",
        "        v[0] = np.sqrt(self._emp_exp_distance[nodes[0], nodes[2]]*self._emp_exp_distance[nodes[1], nodes[3]]*\\\n",
        "                        self._emp_exp_distance[nodes[0], nodes[3]]*self._emp_exp_distance[nodes[1], nodes[2]])/\\\n",
        "                      (self._emp_exp_distance[nodes[0], nodes[1]]*self._emp_exp_distance[nodes[2], nodes[3]])\n",
        "        v[1] = np.sqrt(self._emp_exp_distance[nodes[0], nodes[1]]*self._emp_exp_distance[nodes[2], nodes[3]]*\\\n",
        "                        self._emp_exp_distance[nodes[0], nodes[3]]*self._emp_exp_distance[nodes[1], nodes[2]])/\\\n",
        "                      (self._emp_exp_distance[nodes[0], nodes[2]]*self._emp_exp_distance[nodes[1], nodes[3]])\n",
        "        v[2] = np.sqrt(self._emp_exp_distance[nodes[0], nodes[1]]*self._emp_exp_distance[nodes[2], nodes[3]]*\\\n",
        "                        self._emp_exp_distance[nodes[0], nodes[2]]*self._emp_exp_distance[nodes[1], nodes[3]])/\\\n",
        "                      (self._emp_exp_distance[nodes[0], nodes[3]]*self._emp_exp_distance[nodes[1], nodes[2]])\n",
        "        if bin_p:\n",
        "            print(v, self._thres_star, \"v, thres_star\")\n",
        "        if np.min(v)<self._thres_star:\n",
        "            num_less_1 = sum([int(i<1) for i in v])\n",
        "            if num_less_1 > 1:\n",
        "                return None, [], []\n",
        "            pair1 = [nodes[0], nodes[np.argmin(v)+1]]\n",
        "            pair2 = list(set(nodes) - set(pair1))\n",
        "            return True, pair1, pair2\n",
        "        else:\n",
        "            return False, [], []\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Given the pairwise empirical distributions and 3 input nodes, find their center node.\n",
        "\n",
        "    Inputs:\n",
        "    Empirical pairwise negative exponential distances - _emp_exp_distance\n",
        "    Lists and sets of neighborhood nodes - _prox, _prox_set\n",
        "    Three nodes - l, r, j\n",
        "\n",
        "    Output:\n",
        "\n",
        "    Candidate center nodes - center_cand\n",
        "    \"\"\"\n",
        "    def _find_unidentifiable_center(self, l, r, j):\n",
        "        bin_p = True           # This is a flag to turn on/off debug printing\n",
        "        bin_p = False\n",
        "        center_cand = [l,r,j]\n",
        "        corrected_class = set([])\n",
        "        center_est_1 = None\n",
        "        for i1 in center_cand:\n",
        "            num_star = 0\n",
        "            if i1 not in self.edges_dict:\n",
        "                continue\n",
        "            for i2 in self.edges_dict[i1]:\n",
        "                non_star, pair1, pair2 = self._is_non_star([i2,l,r,j])\n",
        "                dist_i2 = [self._emp_exp_distance[i2, l], self._emp_exp_distance[i2, r], self._emp_exp_distance[i2, j]]\n",
        "                if min(dist_i2)<self._thres_prox:\n",
        "                    continue\n",
        "                if not non_star:\n",
        "                    num_star += 1\n",
        "            if num_star > len(self.edges_dict[i1])/2.0:\n",
        "                center_est_1 = [i1]\n",
        "                for i2 in self.edges_dict[i1]:\n",
        "                    corrected_class.add(frozenset([l,r,j,i2]))\n",
        "                if bin_p:\n",
        "                    print(corrected_class)\n",
        "                break\n",
        "        for tup in self._prox[r]:\n",
        "            i = tup[1]\n",
        "            if i == l or i == j:\n",
        "                continue\n",
        "            if i not in self._prox_set[l] or i not in self._prox_set[j]:\n",
        "                continue\n",
        "            if frozenset([i,l,r,j]) in corrected_class:\n",
        "                non_star, pair1, pair2 = False, [], []\n",
        "            else:\n",
        "                non_star, pair1, pair2 = self._is_non_star([i,l,r,j])\n",
        "            if non_star == None:\n",
        "                continue\n",
        "            if bin_p:\n",
        "                print(self.permutation[i],self.permutation[l],self.permutation[r],self.permutation[j], \"ilrj\", np.array(self.permutation)[pair1], np.array(self.permutation)[pair2], \"pair1, pair2\")\n",
        "            if non_star and i in pair1:\n",
        "                pair1.remove(i)\n",
        "                if pair1[0] in center_cand:\n",
        "                    center_cand.remove(pair1[0])\n",
        "            if non_star and i in pair2:\n",
        "                pair2.remove(i)\n",
        "                if pair2[0] in center_cand:\n",
        "                    center_cand.remove(pair2[0])\n",
        "        if bin_p:\n",
        "            print(center_est_1, \"center_est_1\")\n",
        "        if center_est_1 != None and center_est_1[0] not in center_cand:\n",
        "            return None\n",
        "        return center_cand\n",
        "\n",
        "\n",
        "\n",
        "    def _find_center_quad_supp_4(self, i,j,k):\n",
        "        bin_p = True     # This is a flag for debug printing\n",
        "        bin_p = False \n",
        "        norm = 2\n",
        "        if bin_p:\n",
        "            print(self.permutation[i],self.permutation[j],self.permutation[k])\n",
        "        centers = [i,j,k]\n",
        "        O = np.ones(shape = [4,4])\n",
        "        I = np.identity(4)\n",
        "        \n",
        "        # check if i is the center node\n",
        "        M = np.matmul(self._emp_distribution[i][k], np.matmul(la.inv(self._emp_distribution[j][k]), self._emp_distribution[j][i]))\n",
        "        P = self._emp_distribution[i][i]\n",
        "        A = (O - 4*I)/16\n",
        "        B = -1/4*(np.matmul(O,P) + np.matmul(P,O) - 4*P - I)\n",
        "        C = M - P\n",
        "        # print(A,B,C)\n",
        "        err_i = float('inf')\n",
        "        im_root_flag = False\n",
        "        root = 0\n",
        "        for i1 in range(4):\n",
        "            for i2 in range(4):\n",
        "                p = np.poly1d([A[i1][i2], B[i1][i2], C[i1][i2]])\n",
        "                # print(p)\n",
        "                roots = p.r\n",
        "                # print(roots)\n",
        "                if roots[0].imag > 1e-4:\n",
        "                    im_root_flag = True\n",
        "                if roots[0].real > self.q_max + 0.15 or roots[0].real < -0.15:\n",
        "                    root += roots[1].real/16.0\n",
        "                    continue\n",
        "                if roots[1].real > self.q_max + 0.15 or roots[1].real < -0.15:\n",
        "                    root += roots[0].real/16.0\n",
        "                    continue  \n",
        "                root0_res = A*roots[0].real**2 + B*roots[0].real + C\n",
        "                root1_res = A*roots[1].real**2 + B*roots[1].real + C\n",
        "                if la.norm(root0_res, ord = 'fro')<la.norm(root1_res, ord='fro'):\n",
        "                    root += roots[0].real/16.0\n",
        "                else:\n",
        "                    root += roots[1].real/16.0\n",
        "        if bin_p:\n",
        "            print(self.permutation[i],self.permutation[j],self.permutation[k], root, \"i,j,k,root, icenter\")\n",
        "        if not im_root_flag:# and root.real - self.q_max < 0.1:\n",
        "            residual = A*root.real**2 + B*root.real + C\n",
        "            err_i = la.norm(residual, ord = 'fro')\n",
        "        if err_i>self._thres_quad:\n",
        "            centers.remove(i)\n",
        "\n",
        "\n",
        "        # check if j is the center node\n",
        "        M = np.matmul(self._emp_distribution[j][k], np.matmul(la.inv(self._emp_distribution[i][k]), self._emp_distribution[i][j]))\n",
        "        P = self._emp_distribution[j][j]\n",
        "        A = (O - 4*I)/16\n",
        "        B = -1/4*(np.matmul(O,P) + np.matmul(P,O) - 4*P - I)\n",
        "        C = M - P\n",
        "        err_j = float('inf')\n",
        "        im_root_flag = False\n",
        "        root = 0\n",
        "        for i1 in range(4):\n",
        "            for i2 in range(4):\n",
        "                p = np.poly1d([A[i1][i2], B[i1][i2], C[i1][i2]])\n",
        "                # print(p)\n",
        "                roots = p.r\n",
        "                # if i1 == 0 and i2 == 0:\n",
        "                # print(roots)\n",
        "                if roots[0].imag > 1e-4:\n",
        "                    im_root_flag = True\n",
        "                if roots[0].real > self.q_max + 0.15 or roots[0].real < -0.15:\n",
        "                    root += roots[1].real/16.0\n",
        "                    continue\n",
        "                if roots[1].real > self.q_max + 0.15 or roots[1].real < -0.15:\n",
        "                    root += roots[0].real/16.0\n",
        "                    continue  \n",
        "                root0_res = A*roots[0].real**2 + B*roots[0].real + C\n",
        "                root1_res = A*roots[1].real**2 + B*roots[1].real + C\n",
        "                if la.norm(root0_res, ord = 'fro')<la.norm(root1_res, ord='fro'):\n",
        "                    root += roots[0].real/16.0\n",
        "                else:\n",
        "                    root += roots[1].real/16.0\n",
        "        if bin_p:\n",
        "            print(self.permutation[i],self.permutation[j],self.permutation[k], root, \"i,j,k,root, jcenter\")\n",
        "        if not im_root_flag:# and root.real - self.q_max < 0.1:\n",
        "            residual = A*root.real**2 + B*root.real + C\n",
        "            err_j = la.norm(residual, ord = 'fro')\n",
        "        if err_j>self._thres_quad:\n",
        "            centers.remove(j)\n",
        "\n",
        "        # check if k is the center node\n",
        "        M = np.matmul(self._emp_distribution[k][i], np.matmul(la.inv(self._emp_distribution[j][i]), self._emp_distribution[j][k]))\n",
        "        P = self._emp_distribution[k][k]\n",
        "        A = (O - 4*I)/16\n",
        "        B = -1/4*(np.matmul(O,P) + np.matmul(P,O) - 4*P - I)\n",
        "        C = M - P\n",
        "        err_k = float('inf')\n",
        "        im_root_flag = False\n",
        "        root = 0\n",
        "        for i1 in range(4):\n",
        "            for i2 in range(4):\n",
        "                p = np.poly1d([A[i1][i2], B[i1][i2], C[i1][i2]])\n",
        "                # print(p)\n",
        "                roots = p.r\n",
        "                # print(roots)\n",
        "                if roots[0].imag > 1e-4:\n",
        "                    im_root_flag = True\n",
        "                if roots[0].real > self.q_max + 0.15 or roots[0].real < -0.15:\n",
        "                    root += roots[1].real/16.0\n",
        "                    continue\n",
        "                if roots[1].real > self.q_max + 0.15 or roots[1].real < -0.15:\n",
        "                    root += roots[0].real/16.0\n",
        "                    continue  \n",
        "                root0_res = A*roots[0].real**2 + B*roots[0].real + C\n",
        "                root1_res = A*roots[1].real**2 + B*roots[1].real + C\n",
        "                if la.norm(root0_res, ord = 'fro')<la.norm(root1_res, ord='fro'):\n",
        "                    print(\"root[0]\", la.norm(root0_res, ord = 'fro'), la.norm(root1_res, ord = 'fro'))\n",
        "                    root += roots[0].real/16.0\n",
        "                else:\n",
        "                    root += roots[1].real/16.0\n",
        "        if bin_p:\n",
        "            print(self.permutation[i],self.permutation[j],self.permutation[k], root, \"i,j,k,root, kcenter\")\n",
        "        if not im_root_flag:# and root.real - self.q_max < 0.1:\n",
        "            residual = A*root.real**2 + B*root.real + C\n",
        "            err_k = la.norm(residual, ord = 'fro')\n",
        "        if err_k>self._thres_quad:\n",
        "            centers.remove(k)\n",
        "\n",
        "        return centers, [err_i, err_j, err_k]\n",
        "    \n",
        "\n",
        "    \"\"\"\n",
        "    Finds a pair of leaf and parent nodes from a set of active set of nodes.\n",
        "\n",
        "    Inputs: \n",
        "\n",
        "    Active set of nodes - nodes\n",
        "    Set of previous parent nodes - parents\n",
        "\n",
        "    Outputs: \n",
        "    Leaf node - r\n",
        "    Parent node - l\n",
        "    \"\"\"\n",
        "    def _find_leaf_parent(self, nodes, parents):\n",
        "        bin_p = True             # This is a flag to turn on/off debug printing\n",
        "        bin_p = False \n",
        "        # Arbitrarily choose a node r\n",
        "        r = nodes[0]\n",
        "        for i in parents:\n",
        "            if i in nodes:\n",
        "                r = i\n",
        "                break\n",
        "        prox_copy = copy.deepcopy(self._prox)\n",
        "        # Select closest valid l\n",
        "        l = heapq.heappop(prox_copy[r])[1]\n",
        "        while l not in nodes:\n",
        "            if len(prox_copy[r]) == 0:\n",
        "                return []\n",
        "            l = heapq.heappop(prox_copy[r])[1]\n",
        "        visited = set([l, r])\n",
        "        fix_lr = False\n",
        "        center_resuts = {}\n",
        "        while(1):\n",
        "            if len(prox_copy[r]) == 0:\n",
        "                break\n",
        "            # Choose a third node j\n",
        "            j = heapq.heappop(prox_copy[r])[1]\n",
        "            while j not in nodes or j in visited:\n",
        "                if len(prox_copy[r]) == 0:\n",
        "                    return [l,r]\n",
        "                j = heapq.heappop(prox_copy[r])[1]\n",
        "            visited.add(j)\n",
        "            # Find the center node among l, r, j       \n",
        "            centers = self._find_unidentifiable_center(l,r,j)\n",
        "            if centers == None or len(centers) == 0:\n",
        "                continue\n",
        "            if bin_p:\n",
        "                print(self.permutation[l],self.permutation[r],self.permutation[j], np.array(self.permutation)[centers], \"l,r,j, centers\")\n",
        "            # If there are more than one candidate centers, they have to be in the same leaf cluster\n",
        "            # if len(quad_centers)>1 and len(centers)>1:\n",
        "            if len(centers)>1:\n",
        "                # If the candidate center nodes are l and r, and in any previous iteration, we found the parent node among them, return them in the same order.\n",
        "                if fix_lr and l in centers and r in centers:\n",
        "                    if bin_p:\n",
        "                        print(self.permutation[l], self.permutation[r], \"l, r, fix_lr\")\n",
        "                    return [l,r]\n",
        "                else:\n",
        "                    # If we have found one of the nodes to be a parent node in an earlier iteration, it is selected as a parent node\n",
        "                    parent_exists = False\n",
        "                    for i in centers:\n",
        "                        if i in parents:\n",
        "                            l = i\n",
        "                            parent_exists = True\n",
        "                        if parent_exists:\n",
        "                            centers.remove(i)\n",
        "                            r = centers[0]\n",
        "                            if bin_p:\n",
        "                                print(np.array(self.permutation)[centers], self.permutation[l], self.permutation[r], \"centers, parent exists, l, r\")\n",
        "                            return [l,r]\n",
        "                    if bin_p:\n",
        "                        print(\"parent exists = False\")\n",
        "                    # Find the node with minimum error in Quadratic of Equation 7\n",
        "                    min_err = float('inf')\n",
        "                    pot_lr = [-1, -1]\n",
        "                    \n",
        "                    temp = [-1, -1]\n",
        "                    for temp_iter in range(len(centers)):\n",
        "                        if len(centers) == 2:\n",
        "                            if temp_iter == 1:\n",
        "                                continue\n",
        "                            temp[0] = centers[0]\n",
        "                            temp[1] = centers[1]\n",
        "                        else:\n",
        "                            if temp_iter == 0:\n",
        "                                temp[0] = centers[0]\n",
        "                                temp[1] = centers[1]\n",
        "                            if temp_iter == 1:\n",
        "                                temp[0] = centers[0]\n",
        "                                temp[1] = centers[2]\n",
        "                            if temp_iter == 2:\n",
        "                                temp[0] = centers[2]\n",
        "                                temp[1] = centers[1]\n",
        "                        for i in self._prox[temp[0]]:\n",
        "                            k = i[1]\n",
        "                            \n",
        "                            if k not in self._prox_set[temp[1]] or k not in nodes:\n",
        "                                continue\n",
        "                            # The quadratic test returns the node with the smaller residual as a potential parent node.\n",
        "                            cand_nodes = [temp[0], temp[1], k]\n",
        "\n",
        "                            _, err = self._find_center_quad_supp_4(temp[0], temp[1], k)\n",
        "                            temp_centers = self._find_unidentifiable_center(temp[0], temp[1], k)\n",
        "                            if bin_p:\n",
        "                                print(self.permutation[temp[0]], self.permutation[temp[1]], self.permutation[k], self.permutation[np.array(temp_centers)], \"temp0, temp1, k, centers\")\n",
        "                            if temp_centers and k not in temp_centers:\n",
        "                                err = err[:2]\n",
        "\n",
        "                            if None in err:\n",
        "                                return [-1, -1]\n",
        "                            if min_err > min(err):\n",
        "                                min_err = min(err)\n",
        "                                l = cand_nodes[np.argmin(np.array(err))]\n",
        "                                if l == temp[0]:\n",
        "                                    r = temp[1]\n",
        "                                else:\n",
        "                                    r = temp[0]\n",
        "                                pot_lr = [l, r]\n",
        "                                if bin_p:\n",
        "                                    print(err, \"err\")\n",
        "                                    print([self.permutation[i] for i in pot_lr], \"potential l, r\")\n",
        "\n",
        "                    return pot_lr\n",
        "            # If r is the center node, shift both l and r      \n",
        "            if r in centers:\n",
        "                l, r = r,j\n",
        "                fix_lr = True\n",
        "            # If j is the center node, shift l\n",
        "            elif j in centers:\n",
        "                l = j\n",
        "                fix_lr = True\n",
        "            elif l in centers:\n",
        "                fix_lr = True\n",
        "        return [l, r]\n",
        "\n",
        "\n",
        "    \n",
        "    \"\"\"\n",
        "    This is the complete algorithm. Returns the edges learnt by the algorithm. If the algorithm fails at this stage, it returns an error.\n",
        "\n",
        "    Inputs:\n",
        "\n",
        "    Noisy samples - _noisy_samples\n",
        "\n",
        "    Output:\n",
        "    Edges learnt by the algorithm - edges\n",
        "    Returns an error if the algorithm fails - error\n",
        "\n",
        "    \"\"\"  \n",
        "    def find_tree(self):\n",
        "        bin_p = True         # This is a flag for debug printing\n",
        "        bin_p = False \n",
        "        edges = []\n",
        "        subtree = list(range(self.num_nodes))\n",
        "        error = 0\n",
        "        parents = []\n",
        "        self.edges_dict = {}\n",
        "        self._gen_sample_dist()\n",
        "        self._pairwise_exp_distance()\n",
        "        self._get_prox()\n",
        "        while len(subtree)>2:\n",
        "            # Find a pair of leaf and parent nodes\n",
        "            leaf_parent = self._find_leaf_parent(subtree, parents)\n",
        "            if len(leaf_parent) == 0 or -1 in leaf_parent:\n",
        "                error = -1\n",
        "                break\n",
        "            if bin_p:\n",
        "                print(\"\\n\",self.permutation[leaf_parent[0]], self.permutation[leaf_parent[1]], \"parent leaf\")\n",
        "            # Record the edge\n",
        "            edges.append([self.permutation[leaf_parent[0]], self.permutation[leaf_parent[1]]])\n",
        "            # Remove the leaf node.\n",
        "            subtree.remove(leaf_parent[1])\n",
        "            parents.append(leaf_parent[0])\n",
        "            if leaf_parent[0] not in self.edges_dict:\n",
        "                self.edges_dict[leaf_parent[0]] = [leaf_parent[1]]\n",
        "            else:\n",
        "                self.edges_dict[leaf_parent[0]].append(leaf_parent[1])\n",
        "            if leaf_parent[1] not in self.edges_dict:\n",
        "                self.edges_dict[leaf_parent[1]] = [leaf_parent[0]]\n",
        "            else:\n",
        "                self.edges_dict[leaf_parent[1]].append(leaf_parent[0])\n",
        "        edges.append([self.permutation[subtree[0]], self.permutation[subtree[1]]])\n",
        "        return edges, error\n",
        "  \n",
        "          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah5F6a09F5i3"
      },
      "source": [
        "**Initialize the parameters**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3w1nd6m2ikF"
      },
      "source": [
        "\"\"\"\n",
        "Use the same underlying probability function in each iteration\n",
        "\n",
        "\"\"\"\n",
        "# Initializing parameters and variables\n",
        "rand.seed(3)\n",
        "def init_params():\n",
        "    params = {}                                                                                         # Dictionary of Parameters\n",
        "    params['shape_list'] = ['chain','star','random']                                                    # graph structure: 'chain', 'star', 'random'\n",
        "    params['log_num_samples_list'] = [np.arange(16, 6, -1), np.arange(16, 6, -1), np.arange(16, 6, -1)] # log2 of the number of samples\n",
        "    params['num_nodes'] = 7                                                                             # number of nodes\n",
        "    params['num_iter'] = 50                                                                             # number of runs                                        \n",
        "    params['q_max'] = 0.2                                                                               # maximum probability of corruption for a node\n",
        "    params['deltas'] = [0.02, 0.04]                                                               # values of delta for the perturbed symmetric model\n",
        "    params['cond_det_bounds'] = [0.7,0.7]                                                               # These are the distance upper and lower bounds-current implementation works only with the lower bound.\n",
        "    params['marg'] = True                                                                               # selection of the sampling process - True for small number of nodes (<13) False otherwise\n",
        "    results = {}                                                                                        # Dictionary of results\n",
        "    results['exact_error_list'] = []                                                                    # list of errors of our algorithm in recovering the exact tree. \n",
        "    results['equiv_class_error_list'] = []                                                              # list of errors of our algorithm in recovering a tree from the equivalence class. \n",
        "    results[\"CL_exact_error_list\"] = []                                                                 # list of errors of Chow-Liu algorithm in recovering the exact tree.\n",
        "    results[\"CL_equiv_class_error_list\"] = []                                                           # list of errors of Chow-Liu algorithm in recovering a tree from the equivalence class.\n",
        "    return params, results\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V36tDSJ_9iP"
      },
      "source": [
        "\n",
        "# Code for varying delta for different graph structures\n",
        "def main():\n",
        "    colors = sns.color_palette(\"colorblind\", 8)\n",
        "    params, results = init_params()\n",
        "    n = len(params['deltas'])\n",
        "    m = len(params['shape_list'])\n",
        "    figure, axis = plt.subplots(m, n, figsize = [6*n, 6*m])\n",
        "    num_nodes = params['num_nodes']\n",
        "    q_max = params['q_max']\n",
        "    supp_size = 4\n",
        "    \n",
        "    cond_det_low, cond_det_high = params['cond_det_bounds']\n",
        "    for shape_num, (shape, log_num_samples_list) in enumerate(zip(params['shape_list'], params['log_num_samples_list'])):\n",
        "    # Generate the tree with the given parameters.\n",
        "        num_samples_list = [2**i for i in log_num_samples_list]\n",
        "        tree = Tree(num_nodes, shape)\n",
        "        tree.gen_edges()\n",
        "        print(tree.edges)\n",
        "        exact_tree_edges = tree.edges_as_set_of_sets(tree.edges)\n",
        "        EC = tree.edges_to_EC()\n",
        "        for del_num, delta in enumerate(params['deltas']):\n",
        "            # lam = params['lam_1_lam_2'][0]\n",
        "            \n",
        "            lam_n = (1-q_max)\n",
        "            thres_prox = lam_n**(3*(supp_size - 1))*cond_det_low**4\n",
        "            time_start = time.time()\n",
        "            thres_quad = 10\n",
        "            thres_star = (1+cond_det_high**2)/2\n",
        "            results['exact_error_list'].append([])    \n",
        "            results['equiv_class_error_list'].append([]) \n",
        "            results[\"CL_exact_error_list\"].append([]) \n",
        "            results[\"CL_equiv_class_error_list\"].append([]) \n",
        "            for num_samples in num_samples_list:\n",
        "                \n",
        "                rand.seed(2)\n",
        "                num_error_exact = 0\n",
        "                num_error_equiv_class = 0\n",
        "                CL_exact_error = 0\n",
        "                CL_equiv_class_error = 0\n",
        "                for iter in range(params['num_iter']):\n",
        "                    if iter%25 == 0:\n",
        "                        print(\"################################################################################\", iter)\n",
        "                    # Generate samples for the given parameters\n",
        "\n",
        "                    sampling = MRF_sampling(num_samples, cond_det_low, cond_det_high, q_max, tree.edges, supp_size, delta)\n",
        "                    sampling.gen_cond_dist_perturbed_symmetric()\n",
        "                    sampling.gen_pmf()\n",
        "                    sampling.gen_clean_samples_1()\n",
        "                    sampling.gen_noisy_samples()\n",
        "                    \n",
        "                    # Recover the tree\n",
        "                    permutation = rand.permutation(num_nodes)\n",
        "                    ideal_thres_prox = False\n",
        "                    recover_tree = RecoverTree(sampling.noisy_samples, permutation, thres_quad, thres_prox, thres_star, ideal_thres_prox, q_max, supp_size)\n",
        "                    edges_learnt, error = recover_tree.find_tree()\n",
        "                    recover_tree._pairwise_exp_distance()\n",
        "                    edges_set = tree.edges_as_set_of_sets(edges_learnt)\n",
        "\n",
        "                    # Chow Liu\n",
        "                    recover_tree.pairwise_mut_info()\n",
        "                    CL_edges = tree.invert_permute(tree.chow_liu_tree(recover_tree.emp_mut_info),permutation)\n",
        "                    CL_edges_set = tree.edges_as_set_of_sets(CL_edges)\n",
        "\n",
        "                    # Check for exact recovery of the tree by our algorithm.\n",
        "                    if edges_set != exact_tree_edges or error ==-1:\n",
        "                        num_error_exact += 1\n",
        "\n",
        "                    # Check for the recovery of a tree from the equivalence class by our algorithm.\n",
        "                    if edges_set not in EC or error ==-1:\n",
        "                        num_error_equiv_class += 1\n",
        "\n",
        "                    # Check for exact recovery by the Chow-Liu algorithm.\n",
        "                    if CL_edges_set != exact_tree_edges or error ==-1:\n",
        "                        CL_exact_error += 1\n",
        "     \n",
        "                    # Check for the recovery of a tree from the equivalence class by the Chow-Liu algorithm.\n",
        "                    if CL_edges_set not in EC or error ==-1:\n",
        "                        CL_equiv_class_error += 1\n",
        "                results['exact_error_list'][len(results['exact_error_list'])-1].append(num_error_exact)\n",
        "                results['equiv_class_error_list'][len(results['equiv_class_error_list'])-1].append(num_error_equiv_class)\n",
        "                results['CL_exact_error_list'][len(results['CL_exact_error_list'])-1].append(CL_exact_error)\n",
        "                results['CL_equiv_class_error_list'][len(results['CL_equiv_class_error_list'])-1].append(CL_equiv_class_error)\n",
        "                print(results['exact_error_list'], \"results['exact_error_list']\", num_samples)\n",
        "                print(results['equiv_class_error_list'], \"results['equiv_class_error_list']\")\n",
        "                print(results['CL_exact_error_list'], \"results['CL_exact_error_list']\")\n",
        "                print(results['CL_equiv_class_error_list'], \"results['CL_equiv_class_error_list']\")\n",
        "            axis[shape_num, del_num].plot(num_samples_list, 1-np.array(results['exact_error_list'][len(results['exact_error_list'])-1])/params['num_iter'], label='Our algorithm - Exact', linewidth=3, marker='o', markersize=10, markevery=1, color=colors[2])\n",
        "            axis[shape_num, del_num].plot(num_samples_list, 1-np.array(results['equiv_class_error_list'][len(results['exact_error_list'])-1])/params['num_iter'], label='Our algorithm - EC', linewidth=3, marker='v', markersize=12, markevery=1, color=colors[1])\n",
        "            axis[shape_num, del_num].plot(num_samples_list, 1-np.array(results['CL_exact_error_list'][len(results['exact_error_list'])-1])/params['num_iter'], label='Chow-Liu - Exact', linewidth=3, marker='o', markersize=10, markevery=1, linestyle='--', color=colors[0])\n",
        "            axis[shape_num, del_num].plot(num_samples_list, 1-np.array(results['CL_equiv_class_error_list'][len(results['exact_error_list'])-1])/params['num_iter'], label='Chow-Liu - EC', linewidth=3, marker='v', markersize=12, markevery=1, linestyle='--', color=colors[3])\n",
        "            axis[shape_num, del_num].set_xlabel('Number of samples', size=18)\n",
        "            axis[shape_num, del_num].set_xscale('log')\n",
        "            axis[shape_num, del_num].set_ylabel('Fraction of correct recoveries', size=18)\n",
        "            axis[shape_num, del_num].set_ylim(-0.1,1.1)\n",
        "            axis[shape_num, del_num].set_title(\" $\\delta$ = {delta}, shape = {shape}\".format(delta = delta, shape = shape), size = 18)\n",
        "            print(\"Time Elapsed\", time.time() - time_start, params['num_nodes'], num_samples, results['exact_error_list'], results['equiv_class_error_list'])\n",
        "            handles, labels = axis[shape_num, del_num].get_legend_handles_labels()\n",
        "    figure.tight_layout()\n",
        "    lgd = figure.legend(handles, labels, loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 18})\n",
        "    return figure, axis\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwwu7p_K9_7Z"
      },
      "source": [
        "figure, axis = main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3uqrvLNzAlk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}